#!/usr/bin/env python3
"""
Teste de Performance - Sistema de Identifica√ß√£o de P√°ssaros
Testa performance, carga e escalabilidade do sistema
"""

import requests
import time
import json
import os
import sys
from datetime import datetime
import threading
import statistics
import psutil
import subprocess

class PerformanceTester:
    def __init__(self, base_url="http://localhost:8501"):
        self.base_url = base_url
        self.results = []
        self.performance_metrics = {}
        
    def log_test(self, test_name, status, details=""):
        """Registrar resultado do teste"""
        result = {
            "test": test_name,
            "status": status,
            "details": details,
            "timestamp": datetime.now().isoformat()
        }
        self.results.append(result)
        
        status_icon = "‚úÖ" if status == "PASS" else "‚ùå" if status == "FAIL" else "‚ö†Ô∏è"
        print(f"{status_icon} {test_name}: {status}")
        if details:
            print(f"   üìù {details}")
    
    def test_response_time(self):
        """Teste 1: Tempo de resposta"""
        try:
            response_times = []
            
            # Fazer m√∫ltiplas requisi√ß√µes para calcular tempo m√©dio
            for i in range(10):
                start_time = time.time()
                response = requests.get(self.base_url, timeout=30)
                end_time = time.time()
                
                if response.status_code == 200:
                    response_times.append(end_time - start_time)
                time.sleep(0.1)
            
            if response_times:
                avg_time = statistics.mean(response_times)
                min_time = min(response_times)
                max_time = max(response_times)
                
                self.performance_metrics['response_time'] = {
                    'average': avg_time,
                    'min': min_time,
                    'max': max_time,
                    'samples': len(response_times)
                }
                
                if avg_time < 5.0:
                    self.log_test("Tempo de Resposta", "PASS", f"M√©dia: {avg_time:.3f}s, Min: {min_time:.3f}s, Max: {max_time:.3f}s")
                    return True
                else:
                    self.log_test("Tempo de Resposta", "FAIL", f"M√©dia: {avg_time:.3f}s, Min: {min_time:.3f}s, Max: {max_time:.3f}s")
                    return False
            else:
                self.log_test("Tempo de Resposta", "FAIL", "Nenhuma resposta v√°lida recebida")
                return False
        except Exception as e:
            self.log_test("Tempo de Resposta", "FAIL", str(e))
            return False
    
    def test_throughput(self):
        """Teste 2: Taxa de transfer√™ncia"""
        try:
            # Testar throughput com m√∫ltiplas requisi√ß√µes simult√¢neas
            start_time = time.time()
            success_count = 0
            total_requests = 20
            
            def make_request():
                nonlocal success_count
                try:
                    response = requests.get(self.base_url, timeout=10)
                    if response.status_code == 200:
                        success_count += 1
                except:
                    pass
            
            # Fazer requisi√ß√µes simult√¢neas
            threads = []
            for i in range(total_requests):
                thread = threading.Thread(target=make_request)
                threads.append(thread)
                thread.start()
            
            # Aguardar todas as threads
            for thread in threads:
                thread.join()
            
            end_time = time.time()
            total_time = end_time - start_time
            throughput = success_count / total_time
            
            self.performance_metrics['throughput'] = {
                'requests_per_second': throughput,
                'total_requests': total_requests,
                'successful_requests': success_count,
                'total_time': total_time
            }
            
            if throughput >= 2.0:
                self.log_test("Taxa de Transfer√™ncia", "PASS", f"{throughput:.2f} req/s, {success_count}/{total_requests} sucessos")
                return True
            else:
                self.log_test("Taxa de Transfer√™ncia", "FAIL", f"{throughput:.2f} req/s, {success_count}/{total_requests} sucessos")
                return False
        except Exception as e:
            self.log_test("Taxa de Transfer√™ncia", "FAIL", str(e))
            return False
    
    def test_concurrent_users(self):
        """Teste 3: Usu√°rios concorrentes"""
        try:
            # Simular usu√°rios concorrentes
            concurrent_users = 5
            success_count = 0
            total_requests = concurrent_users * 4  # 4 requisi√ß√µes por usu√°rio
            
            def simulate_user(user_id):
                nonlocal success_count
                for i in range(4):
                    try:
                        response = requests.get(self.base_url, timeout=10)
                        if response.status_code == 200:
                            success_count += 1
                        time.sleep(0.5)
                    except:
                        pass
            
            # Simular usu√°rios concorrentes
            threads = []
            for user_id in range(concurrent_users):
                thread = threading.Thread(target=simulate_user, args=(user_id,))
                threads.append(thread)
                thread.start()
            
            # Aguardar todas as threads
            for thread in threads:
                thread.join()
            
            success_rate = success_count / total_requests
            
            self.performance_metrics['concurrent_users'] = {
                'concurrent_users': concurrent_users,
                'total_requests': total_requests,
                'successful_requests': success_count,
                'success_rate': success_rate
            }
            
            if success_rate >= 0.8:
                self.log_test("Usu√°rios Concorrentes", "PASS", f"{concurrent_users} usu√°rios, {success_rate:.2%} taxa de sucesso")
                return True
            else:
                self.log_test("Usu√°rios Concorrentes", "FAIL", f"{concurrent_users} usu√°rios, {success_rate:.2%} taxa de sucesso")
                return False
        except Exception as e:
            self.log_test("Usu√°rios Concorrentes", "FAIL", str(e))
            return False
    
    def test_memory_usage(self):
        """Teste 4: Uso de mem√≥ria"""
        try:
            # Verificar uso de mem√≥ria do sistema
            memory_info = psutil.virtual_memory()
            memory_usage_percent = memory_info.percent
            available_memory = memory_info.available / (1024**3)  # GB
            
            self.performance_metrics['memory_usage'] = {
                'usage_percent': memory_usage_percent,
                'available_gb': available_memory,
                'total_gb': memory_info.total / (1024**3)
            }
            
            if memory_usage_percent < 90:
                self.log_test("Uso de Mem√≥ria", "PASS", f"{memory_usage_percent:.1f}% usado, {available_memory:.1f}GB dispon√≠vel")
                return True
            else:
                self.log_test("Uso de Mem√≥ria", "WARN", f"{memory_usage_percent:.1f}% usado, {available_memory:.1f}GB dispon√≠vel")
                return False
        except Exception as e:
            self.log_test("Uso de Mem√≥ria", "FAIL", str(e))
            return False
    
    def test_cpu_usage(self):
        """Teste 5: Uso de CPU"""
        try:
            # Verificar uso de CPU
            cpu_percent = psutil.cpu_percent(interval=1)
            
            self.performance_metrics['cpu_usage'] = {
                'usage_percent': cpu_percent
            }
            
            if cpu_percent < 80:
                self.log_test("Uso de CPU", "PASS", f"{cpu_percent:.1f}% usado")
                return True
            else:
                self.log_test("Uso de CPU", "WARN", f"{cpu_percent:.1f}% usado")
                return False
        except Exception as e:
            self.log_test("Uso de CPU", "FAIL", str(e))
            return False
    
    def test_load_time(self):
        """Teste 6: Tempo de carregamento"""
        try:
            load_times = []
            
            # Testar tempo de carregamento com diferentes tamanhos de conte√∫do
            for i in range(5):
                start_time = time.time()
                response = requests.get(self.base_url, timeout=30)
                end_time = time.time()
                
                if response.status_code == 200:
                    load_time = end_time - start_time
                    content_size = len(response.content)
                    load_times.append({
                        'time': load_time,
                        'size': content_size
                    })
                time.sleep(1)
            
            if load_times:
                avg_load_time = statistics.mean([lt['time'] for lt in load_times])
                avg_content_size = statistics.mean([lt['size'] for lt in load_times])
                
                self.performance_metrics['load_time'] = {
                    'average_time': avg_load_time,
                    'average_size': avg_content_size,
                    'samples': len(load_times)
                }
                
                if avg_load_time < 3.0:
                    self.log_test("Tempo de Carregamento", "PASS", f"M√©dia: {avg_load_time:.3f}s, Tamanho: {avg_content_size:.0f} bytes")
                    return True
                else:
                    self.log_test("Tempo de Carregamento", "FAIL", f"M√©dia: {avg_load_time:.3f}s, Tamanho: {avg_content_size:.0f} bytes")
                    return False
            else:
                self.log_test("Tempo de Carregamento", "FAIL", "Nenhuma medi√ß√£o v√°lida")
                return False
        except Exception as e:
            self.log_test("Tempo de Carregamento", "FAIL", str(e))
            return False
    
    def test_scalability(self):
        """Teste 7: Escalabilidade"""
        try:
            # Testar escalabilidade com diferentes cargas
            scalability_results = []
            
            for load_level in [1, 5, 10]:
                start_time = time.time()
                success_count = 0
                total_requests = load_level * 2
                
                def make_request():
                    nonlocal success_count
                    try:
                        response = requests.get(self.base_url, timeout=5)
                        if response.status_code == 200:
                            success_count += 1
                    except:
                        pass
                
                # Fazer requisi√ß√µes simult√¢neas
                threads = []
                for i in range(total_requests):
                    thread = threading.Thread(target=make_request)
                    threads.append(thread)
                    thread.start()
                
                # Aguardar todas as threads
                for thread in threads:
                    thread.join()
                
                end_time = time.time()
                total_time = end_time - start_time
                success_rate = success_count / total_requests
                
                scalability_results.append({
                    'load_level': load_level,
                    'success_rate': success_rate,
                    'total_time': total_time
                })
                
                time.sleep(1)
            
            # Verificar se a escalabilidade √© mantida
            success_rates = [sr['success_rate'] for sr in scalability_results]
            min_success_rate = min(success_rates)
            
            self.performance_metrics['scalability'] = {
                'results': scalability_results,
                'min_success_rate': min_success_rate
            }
            
            if min_success_rate >= 0.7:
                self.log_test("Escalabilidade", "PASS", f"Taxa m√≠nima de sucesso: {min_success_rate:.2%}")
                return True
            else:
                self.log_test("Escalabilidade", "FAIL", f"Taxa m√≠nima de sucesso: {min_success_rate:.2%}")
                return False
        except Exception as e:
            self.log_test("Escalabilidade", "FAIL", str(e))
            return False
    
    def test_stress_test(self):
        """Teste 8: Teste de estresse"""
        try:
            # Teste de estresse com alta carga
            stress_duration = 30  # segundos
            start_time = time.time()
            success_count = 0
            total_requests = 0
            
            while time.time() - start_time < stress_duration:
                try:
                    response = requests.get(self.base_url, timeout=5)
                    total_requests += 1
                    if response.status_code == 200:
                        success_count += 1
                except:
                    total_requests += 1
                
                time.sleep(0.1)
            
            success_rate = success_count / total_requests if total_requests > 0 else 0
            
            self.performance_metrics['stress_test'] = {
                'duration': stress_duration,
                'total_requests': total_requests,
                'successful_requests': success_count,
                'success_rate': success_rate
            }
            
            if success_rate >= 0.8:
                self.log_test("Teste de Estresse", "PASS", f"{stress_duration}s, {success_rate:.2%} taxa de sucesso")
                return True
            else:
                self.log_test("Teste de Estresse", "FAIL", f"{stress_duration}s, {success_rate:.2%} taxa de sucesso")
                return False
        except Exception as e:
            self.log_test("Teste de Estresse", "FAIL", str(e))
            return False
    
    def test_resource_efficiency(self):
        """Teste 9: Efici√™ncia de recursos"""
        try:
            # Verificar efici√™ncia de recursos
            memory_info = psutil.virtual_memory()
            cpu_percent = psutil.cpu_percent(interval=1)
            
            # Fazer uma requisi√ß√£o e medir recursos
            start_time = time.time()
            response = requests.get(self.base_url, timeout=10)
            end_time = time.time()
            
            response_time = end_time - start_time
            content_size = len(response.content)
            
            # Calcular efici√™ncia
            efficiency_score = content_size / response_time if response_time > 0 else 0
            
            self.performance_metrics['resource_efficiency'] = {
                'response_time': response_time,
                'content_size': content_size,
                'efficiency_score': efficiency_score,
                'memory_usage': memory_info.percent,
                'cpu_usage': cpu_percent
            }
            
            if efficiency_score > 1000:  # bytes por segundo
                self.log_test("Efici√™ncia de Recursos", "PASS", f"Score: {efficiency_score:.0f} bytes/s")
                return True
            else:
                self.log_test("Efici√™ncia de Recursos", "FAIL", f"Score: {efficiency_score:.0f} bytes/s")
                return False
        except Exception as e:
            self.log_test("Efici√™ncia de Recursos", "FAIL", str(e))
            return False
    
    def test_performance_consistency(self):
        """Teste 10: Consist√™ncia de performance"""
        try:
            # Testar consist√™ncia de performance ao longo do tempo
            performance_samples = []
            
            for i in range(10):
                start_time = time.time()
                response = requests.get(self.base_url, timeout=10)
                end_time = time.time()
                
                if response.status_code == 200:
                    response_time = end_time - start_time
                    performance_samples.append(response_time)
                
                time.sleep(1)
            
            if performance_samples:
                avg_performance = statistics.mean(performance_samples)
                std_performance = statistics.stdev(performance_samples)
                coefficient_of_variation = std_performance / avg_performance if avg_performance > 0 else 0
                
                self.performance_metrics['performance_consistency'] = {
                    'average': avg_performance,
                    'standard_deviation': std_performance,
                    'coefficient_of_variation': coefficient_of_variation,
                    'samples': len(performance_samples)
                }
                
                if coefficient_of_variation < 0.5:  # Menos de 50% de varia√ß√£o
                    self.log_test("Consist√™ncia de Performance", "PASS", f"CV: {coefficient_of_variation:.3f}")
                    return True
                else:
                    self.log_test("Consist√™ncia de Performance", "FAIL", f"CV: {coefficient_of_variation:.3f}")
                    return False
            else:
                self.log_test("Consist√™ncia de Performance", "FAIL", "Nenhuma amostra v√°lida")
                return False
        except Exception as e:
            self.log_test("Consist√™ncia de Performance", "FAIL", str(e))
            return False
    
    def run_all_tests(self):
        """Executar todos os testes de performance"""
        print("‚ö° INICIANDO TESTES DE PERFORMANCE")
        print("=" * 60)
        
        tests = [
            self.test_response_time,
            self.test_throughput,
            self.test_concurrent_users,
            self.test_memory_usage,
            self.test_cpu_usage,
            self.test_load_time,
            self.test_scalability,
            self.test_stress_test,
            self.test_resource_efficiency,
            self.test_performance_consistency
        ]
        
        passed = 0
        failed = 0
        warned = 0
        
        for test in tests:
            try:
                result = test()
                if result:
                    passed += 1
                else:
                    failed += 1
            except Exception as e:
                self.log_test(test.__name__, "FAIL", str(e))
                failed += 1
            
            time.sleep(1)  # Pausa entre testes
        
        # Resumo
        print("\n" + "=" * 60)
        print("üìä RESUMO DOS TESTES DE PERFORMANCE")
        print("=" * 60)
        print(f"‚úÖ Passou: {passed}")
        print(f"‚ùå Falhou: {failed}")
        print(f"‚ö†Ô∏è Avisos: {warned}")
        print(f"üìà Taxa de Sucesso: {(passed/(passed+failed)*100):.1f}%")
        
        # Salvar resultados
        self.save_results()
        
        return passed, failed, warned
    
    def save_results(self):
        """Salvar resultados em arquivo JSON"""
        try:
            results_data = {
                "timestamp": datetime.now().isoformat(),
                "results": self.results,
                "performance_metrics": self.performance_metrics
            }
            
            with open("test_results_performance.json", "w") as f:
                json.dump(results_data, f, indent=2, ensure_ascii=False)
            print(f"\nüíæ Resultados salvos em: test_results_performance.json")
        except Exception as e:
            print(f"‚ùå Erro ao salvar resultados: {e}")

def main():
    """Fun√ß√£o principal"""
    print("‚ö° TESTE DE PERFORMANCE - SISTEMA DE IDENTIFICA√á√ÉO DE P√ÅSSAROS")
    print("=" * 70)
    
    tester = PerformanceTester()
    
    try:
        passed, failed, warned = tester.run_all_tests()
        
        if failed == 0:
            print("\nüéâ TODOS OS TESTES DE PERFORMANCE PASSARAM!")
            sys.exit(0)
        else:
            print(f"\n‚ö†Ô∏è {failed} TESTES DE PERFORMANCE FALHARAM")
            sys.exit(1)
            
    except KeyboardInterrupt:
        print("\n‚èπÔ∏è Testes interrompidos pelo usu√°rio")
        sys.exit(1)
    except Exception as e:
        print(f"\n‚ùå Erro inesperado: {e}")
        sys.exit(1)

if __name__ == "__main__":
    main()
